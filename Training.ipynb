{"cells":[{"cell_type":"code","source":["%cd /content/drive/MyDrive/FC_4_mine"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E30TDj6opLKJ","executionInfo":{"status":"ok","timestamp":1650871900757,"user_tz":-180,"elapsed":255,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}},"outputId":"f96ef522-2205-4c24-ec0c-a06933698e7c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/FC_4_mine\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RZXeQEKFnd2i","executionInfo":{"status":"ok","timestamp":1650871908239,"user_tz":-180,"elapsed":7135,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["import math\n","import os\n","import torch\n","import numpy as np\n","import scipy.io\n","import time\n","import re\n","import pandas as pd\n","import cv2\n","\n","import torch.utils.data as data\n","import torchvision.transforms.functional as F\n","import torchvision.models as models\n","\n","from torch import nn, Tensor\n","from torch.nn.functional import normalize as norma\n","from torch.nn.functional import interpolate\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"aHDkKqEOnd2n"},"source":["## Utils"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VVZdFuiNnd2o","executionInfo":{"status":"ok","timestamp":1650871908240,"user_tz":-180,"elapsed":12,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["def normalize(image):\n","    return np.clip(image, 0.0, 65535.0) * (1.0 / 65535.0)\n","\n","def bgr_to_rgb(image):\n","    return image[:, :, ::-1]\n","#?\n","def linear_to_nonlinear(image):\n","    if isinstance(image, np.ndarray):\n","        return np.power(image, (1.0 / 2.2))\n","    if isinstance(image, Tensor):\n","        return torch.pow(image, 1.0 / 2.2)\n","    return F.to_pil_image(torch.pow(F.to_tensor(image), 1.0 / 2.2).squeeze(), mode=\"RGB\")\n","\n","def hwc_to_chw(image):\n","    return image.transpose(2, 0, 1)\n","\n","def scale(image):\n","    image = image - image.min()\n","    image = image / image.max()\n","    return image\n","\n","def rescale(image, size):\n","    return interpolate(image, size, mode='bilinear')\n","\n","def correct(image,illuminant):\n","    image = F.to_tensor(image).to(DEVICE)\n","\n","    #Correcting image\n","    correction = illuminant.unsqueeze(2).unsqueeze(3) * torch.sqrt(Tensor([3])).to(DEVICE)\n","    corrected_img = torch.div(image, correction + 1e-10)\n","\n","    #Normalization\n","    max_img = torch.max(torch.max(torch.max(corrected_img, dim=1)[0], dim=1)[0], dim=1)[0] + 1e-10\n","    max_img = max_img.unsqueeze(1).unsqueeze(1).unsqueeze(1)\n","    normalized_img = torch.div(corrected_img, max_img)\n","\n","    return F.to_pil_image(linear_to_nonlinear(normalized_img).squeeze(), mode=\"RGB\")\n","\n","def percentile(errors, procents):\n","    return np.percentile(errors, procents * 100)\n","\n","def compute_metrics(errors):\n","    errors = sorted(errors)\n","    metrics = {\n","        \"mean\": np.mean(errors),\n","        \"median\": percentile(errors, 0.5),\n","        \"trimean\": 0.25 * (percentile(errors, 0.25) + 2 * percentile(errors, 0.5) + percentile(errors, 0.75)),\n","        \"bst25\": np.mean(errors[:int(0.25 * len(errors))]),\n","        \"wst25\": np.mean(errors[int(0.75 * len(errors)):]),\n","        \"wst5\": percentile(errors, 0.95)}\n","    return metrics\n","\n","def print_metrics(current_metrics):\n","    print(\" Mean ......... : {:.4f} \".format(current_metrics[\"mean\"]))\n","    print(\" Median ....... : {:.4f} \".format(current_metrics[\"median\"]))\n","    print(\" Trimean ...... : {:.4f} \".format(current_metrics[\"trimean\"]))\n","    print(\" Best 25% ..... : {:.4f} \".format(current_metrics[\"bst25\"]))\n","    print(\" Worst 25% .... : {:.4f} \".format(current_metrics[\"wst25\"]))\n","    print(\" Worst 5% ..... : {:.4f} \".format(current_metrics[\"wst5\"]))\n","\n","def normalize(image):\n","    max_int = 65535.0\n","    return np.clip(image, 0.0, max_int) * (1.0 / max_int)"]},{"cell_type":"markdown","metadata":{"id":"8oSkByfynd2q"},"source":["## Dataset class"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"N95A-2stnd2r","executionInfo":{"status":"ok","timestamp":1650871908240,"user_tz":-180,"elapsed":9,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["class ColorCheckerDataset(data.Dataset):\n","\n","    def __init__(self, train = True, folds_num = 1):\n","\n","        self.__train = train\n","  \n","\n","        path_to_folds = os.path.join(\"dataset\", \"folds.mat\")\n","        path_to_metadata = os.path.join(\"dataset\", \"metadata.txt\")\n","        self.__path_to_data = os.path.join(\"dataset\", \"preprocessed\", \"numpy_data\")\n","        self.__path_to_label = os.path.join(\"dataset\", \"preprocessed\", \"numpy_labels\")\n","\n","        folds = scipy.io.loadmat(path_to_folds)\n","        img_idx = folds[\"tr_split\" if self.__train else \"te_split\"][0][folds_num][0]\n","\n","        metadata = open(path_to_metadata, 'r').readlines()\n","        self.__fold_data = [metadata[i - 1] for i in img_idx]\n","\n","    def __getitem__(self, index):\n","        file_name = self.__fold_data[index].strip().split(' ')[1]\n","        img = np.array(np.load(os.path.join(self.__path_to_data, file_name + '.npy')), dtype='float32')\n","        illuminant = np.array(np.load(os.path.join(self.__path_to_label, file_name + '.npy')), dtype='float32')\n","\n","        if self.__train:\n","            img, illuminant = img, illuminant\n","        else:\n","            img = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n","\n","        img = hwc_to_chw(linear_to_nonlinear(bgr_to_rgb(normalize(img))))\n","\n","        img = torch.from_numpy(img.copy())\n","        illuminant = torch.from_numpy(illuminant.copy())\n","\n","        if not self.__train:\n","            img = img.type(torch.FloatTensor)\n","\n","        return img, illuminant, file_name\n","   \n","    def __len__(self):\n","        return len(self.__fold_data)"]},{"cell_type":"markdown","metadata":{"id":"_Jr6HuZUnd2s"},"source":["## ModelFC4 class"]},{"cell_type":"markdown","metadata":{"id":"Wv6Tch3tnd2s"},"source":["Module:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kwK3dYQWnd2t","executionInfo":{"status":"ok","timestamp":1650871908241,"user_tz":-180,"elapsed":9,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["class FC4(torch.nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        #Alexnet\n","        alexnet = models.alexnet(pretrained=True)\n","        self.backbone = nn.Sequential(*list(alexnet.children())[0])\n","\n","        #Additional layers\n","        self.final_convs = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=2, stride=1, ceil_mode=True),\n","            nn.Conv2d(256, 64, kernel_size=6, stride=1, padding=3),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.5),\n","            nn.Conv2d(64, 4, kernel_size=1, stride=1),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, image):\n","        \"\"\"\n","        Estimate an RGB colour for the illuminant of the input image\n","        @param x: the image for which the colour of the illuminant has to be estimated\n","        @return: the colour estimate as a Tensor. If confidence-weighted pooling is used, the per-path colour estimates\n","        and the confidence weights are returned as well (used for visualizations)\n","        \"\"\"\n","\n","        image = self.backbone(image)\n","        out = self.final_convs(image)\n"," \n","        # Per-patch color estimates (first 3 dimensions)\n","        rgb = norma(out[:, :3, :, :], dim=1)\n","\n","        # Confidence (last dimension)\n","        confidence = out[:, 3:4, :, :]\n","\n","        # Confidence-weighted pooling\n","        pred = norma(torch.sum(torch.sum(rgb * confidence, 2), 2), dim=1)\n","\n","        return pred, rgb, confidence"]},{"cell_type":"markdown","metadata":{"id":"LC7m1k7und2u"},"source":["FC4 model:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bwieEi-2nd2u","executionInfo":{"status":"ok","timestamp":1650871908241,"user_tz":-180,"elapsed":8,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["class ModelFC4:\n","\n","    def __init__(self):\n","        self._device = \"cuda:0\"\n","        self._optimizer = None\n","        self._network = FC4().to(self._device)\n","\n","    def predict(self, image):\n","        \"\"\"\n","        Performs inference on the input image using the FC4 method.\n","        @param image: the image for which an illuminant colour has to be estimated\n","        @param return_steps: whether or not to also return the per-patch estimates and confidence weights. When this\n","        flag is set to True, confidence-weighted pooling must be active)\n","        @return: the colour estimate as a Tensor. If \"return_steps\" is set to true, the per-path colour estimates and\n","        the confidence weights are also returned (used for visualizations)\n","        \"\"\"\n","\n","        pred, rgb, confidence = self._network(image)\n","        return pred\n","\n","    def optimize(self, image, true):\n","        self._optimizer.zero_grad()\n","        pred = self.predict(image)\n","        loss = self.get_loss(pred, true)\n","        loss.backward()\n","        self._optimizer.step()\n","        return loss.item()\n","\n","    def get_loss(self, pred, true, safe_v = 0.999999):\n","        dot = torch.clamp(torch.sum(norma(pred, dim=1) * norma(true, dim=1), dim=1), -safe_v, safe_v)\n","        angle = torch.acos(dot) * (180 / math.pi)\n","        return torch.mean(angle).to(self._device)\n","\n","    def train_mode(self):\n","        self._network = self._network.train()\n","\n","    def evaluation_mode(self):\n","        self._network = self._network.eval()\n","\n","    def set_optimizer(self, learning_rate: float, optimizer_type: str = \"adam\"):\n","        optimizers_map = {\"adam\": torch.optim.Adam, \"rmsprop\": torch.optim.RMSprop}\n","        self._optimizer = optimizers_map[optimizer_type](self._network.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"cGN-S1Mfnd2v"},"source":["## Device and random seed"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"vPXobngdnd2v","executionInfo":{"status":"ok","timestamp":1650871908242,"user_tz":-180,"elapsed":9,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"outputs":[],"source":["seed = 0\n","DEVICE = \"cuda:0\"\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"5RP-bTCund2w"},"source":["## Train"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1ce3ab0036d846bda693f226fa75cdc4","8666408c9903449ab5c7b0c13930a756","cdc87b7187fd4c17be4bd91891aee2b0","7698cb66aa174de1b64066c4fc232d10","16bac13981a04295b6154846a50044b0","f138b3286178493c93b9dac31f15a068","3b8c2062c20d44ed966e42c8565f7570","d6369962eefa492a975cde1a363c8a16","aa5271a172644112a038495d8b2edb32","8d37ece3ebff4a08b4973544d8eac121","0fc17e13e2244b5dab90ea9b90195a3c"]},"id":"bofiNwddnd2x","executionInfo":{"status":"error","timestamp":1650873086991,"user_tz":-180,"elapsed":1178757,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}},"outputId":"cb5ac159-dc7c-4870-d107-f4f5cca6ce1c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/233M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce3ab0036d846bda693f226fa75cdc4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["[ Epoch: 0/560 - Batch: 0 ] | [ Train loss: 12.8614 ]\n","[ Epoch: 0/560 - Batch: 5 ] | [ Train loss: 37.5569 ]\n","[ Epoch: 0/560 - Batch: 10 ] | [ Train loss: 32.4413 ]\n","[ Epoch: 0/560 - Batch: 15 ] | [ Train loss: 21.3909 ]\n","[ Epoch: 0/560 - Batch: 20 ] | [ Train loss: 36.8739 ]\n","[ Epoch: 0/560 - Batch: 25 ] | [ Train loss: 27.8238 ]\n","[ Epoch: 0/560 - Batch: 30 ] | [ Train loss: 31.9994 ]\n","[ Epoch: 0/560 - Batch: 35 ] | [ Train loss: 17.4985 ]\n","[ Epoch: 0/560 - Batch: 40 ] | [ Train loss: 3.4261 ]\n","[ Epoch: 0/560 - Batch: 45 ] | [ Train loss: 3.4889 ]\n","[ Epoch: 0/560 - Batch: 50 ] | [ Train loss: 3.9407 ]\n","[ Epoch: 0/560 - Batch: 55 ] | [ Train loss: 6.3619 ]\n","[ Epoch: 0/560 - Batch: 60 ] | [ Train loss: 4.1966 ]\n","[ Epoch: 0/560 - Batch: 65 ] | [ Train loss: 17.0431 ]\n","[ Epoch: 0/560 - Batch: 70 ] | [ Train loss: 1.2527 ]\n","[ Epoch: 0/560 - Batch: 75 ] | [ Train loss: 0.3369 ]\n","[ Epoch: 0/560 - Batch: 80 ] | [ Train loss: 1.4583 ]\n","[ Epoch: 0/560 - Batch: 85 ] | [ Train loss: 7.3370 ]\n","[ Epoch: 0/560 - Batch: 90 ] | [ Train loss: 19.3264 ]\n","[ Epoch: 0/560 - Batch: 95 ] | [ Train loss: 13.3149 ]\n","[ Epoch: 0/560 - Batch: 100 ] | [ Train loss: 2.9386 ]\n","[ Epoch: 0/560 - Batch: 105 ] | [ Train loss: 2.2601 ]\n","[ Epoch: 0/560 - Batch: 110 ] | [ Train loss: 0.6709 ]\n","[ Epoch: 0/560 - Batch: 115 ] | [ Train loss: 16.0488 ]\n","[ Epoch: 0/560 - Batch: 120 ] | [ Train loss: 2.7883 ]\n","[ Epoch: 0/560 - Batch: 125 ] | [ Train loss: 2.1990 ]\n","[ Epoch: 0/560 - Batch: 130 ] | [ Train loss: 22.7328 ]\n","[ Epoch: 0/560 - Batch: 135 ] | [ Train loss: 2.5774 ]\n","[ Epoch: 0/560 - Batch: 140 ] | [ Train loss: 16.5695 ]\n","[ Epoch: 0/560 - Batch: 145 ] | [ Train loss: 4.4558 ]\n","[ Epoch: 0/560 - Batch: 150 ] | [ Train loss: 5.1703 ]\n","[ Epoch: 0/560 - Batch: 155 ] | [ Train loss: 4.3831 ]\n","[ Epoch: 0/560 - Batch: 160 ] | [ Train loss: 33.1625 ]\n","[ Epoch: 0/560 - Batch: 165 ] | [ Train loss: 28.9259 ]\n","[ Epoch: 0/560 - Batch: 170 ] | [ Train loss: 11.5368 ]\n","[ Epoch: 0/560 - Batch: 175 ] | [ Train loss: 2.1934 ]\n","[ Epoch: 0/560 - Batch: 180 ] | [ Train loss: 2.4070 ]\n","[ Epoch: 0/560 - Batch: 185 ] | [ Train loss: 2.7354 ]\n","[ Epoch: 0/560 - Batch: 190 ] | [ Train loss: 3.7809 ]\n","[ Epoch: 0/560 - Batch: 195 ] | [ Train loss: 20.5419 ]\n","[ Epoch: 0/560 - Batch: 200 ] | [ Train loss: 6.4755 ]\n","[ Epoch: 0/560 - Batch: 205 ] | [ Train loss: 3.8716 ]\n","[ Epoch: 0/560 - Batch: 210 ] | [ Train loss: 2.2191 ]\n","[ Epoch: 0/560 - Batch: 215 ] | [ Train loss: 0.6743 ]\n","[ Epoch: 0/560 - Batch: 220 ] | [ Train loss: 2.5966 ]\n","[ Epoch: 0/560 - Batch: 225 ] | [ Train loss: 0.9966 ]\n","[ Epoch: 0/560 - Batch: 230 ] | [ Train loss: 1.3626 ]\n","[ Epoch: 0/560 - Batch: 235 ] | [ Train loss: 2.6873 ]\n","[ Epoch: 0/560 - Batch: 240 ] | [ Train loss: 3.7319 ]\n","[ Epoch: 0/560 - Batch: 245 ] | [ Train loss: 22.4775 ]\n","[ Epoch: 0/560 - Batch: 250 ] | [ Train loss: 22.5958 ]\n","[ Epoch: 0/560 - Batch: 255 ] | [ Train loss: 20.4564 ]\n","[ Epoch: 0/560 - Batch: 260 ] | [ Train loss: 0.7250 ]\n","[ Epoch: 0/560 - Batch: 265 ] | [ Train loss: 31.0756 ]\n","[ Epoch: 0/560 - Batch: 270 ] | [ Train loss: 7.7236 ]\n","[ Epoch: 0/560 - Batch: 275 ] | [ Train loss: 2.8453 ]\n","[ Epoch: 0/560 - Batch: 280 ] | [ Train loss: 22.6877 ]\n","[ Epoch: 0/560 - Batch: 285 ] | [ Train loss: 2.0055 ]\n","[ Epoch: 0/560 - Batch: 290 ] | [ Train loss: 4.1062 ]\n","[ Epoch: 0/560 - Batch: 295 ] | [ Train loss: 2.1086 ]\n","[ Epoch: 0/560 - Batch: 300 ] | [ Train loss: 4.9014 ]\n","[ Epoch: 0/560 - Batch: 305 ] | [ Train loss: 2.0293 ]\n","[ Epoch: 0/560 - Batch: 310 ] | [ Train loss: 8.6398 ]\n","[ Epoch: 0/560 - Batch: 315 ] | [ Train loss: 32.6822 ]\n","[ Epoch: 0/560 - Batch: 320 ] | [ Train loss: 30.5542 ]\n","[ Epoch: 0/560 - Batch: 325 ] | [ Train loss: 2.6098 ]\n","[ Epoch: 0/560 - Batch: 330 ] | [ Train loss: 7.4633 ]\n","[ Epoch: 0/560 - Batch: 335 ] | [ Train loss: 1.8155 ]\n","[ Epoch: 0/560 - Batch: 340 ] | [ Train loss: 20.1140 ]\n","[ Epoch: 0/560 - Batch: 345 ] | [ Train loss: 0.8381 ]\n","[ Epoch: 0/560 - Batch: 350 ] | [ Train loss: 2.6248 ]\n","[ Epoch: 0/560 - Batch: 355 ] | [ Train loss: 21.4624 ]\n","[ Epoch: 0/560 - Batch: 360 ] | [ Train loss: 22.8986 ]\n","[ Epoch: 0/560 - Batch: 365 ] | [ Train loss: 21.5697 ]\n","[ Epoch: 0/560 - Batch: 370 ] | [ Train loss: 3.8716 ]\n","[ Epoch: 0/560 - Batch: 375 ] | [ Train loss: 1.7499 ]\n","\n","--------------------------------------------------------------\n","\t\t\t Validation\n","--------------------------------------------------------------\n","\n","[ Epoch: 0/560 - Batch: 0] | Val loss: 3.6370 ]\n","[ Epoch: 0/560 - Batch: 5] | Val loss: 7.9576 ]\n","[ Epoch: 0/560 - Batch: 10] | Val loss: 3.6294 ]\n","[ Epoch: 0/560 - Batch: 15] | Val loss: 2.3198 ]\n","[ Epoch: 0/560 - Batch: 20] | Val loss: 11.0592 ]\n","[ Epoch: 0/560 - Batch: 25] | Val loss: 7.3695 ]\n","[ Epoch: 0/560 - Batch: 30] | Val loss: 5.6077 ]\n","[ Epoch: 0/560 - Batch: 35] | Val loss: 3.6626 ]\n","[ Epoch: 0/560 - Batch: 40] | Val loss: 4.2736 ]\n","[ Epoch: 0/560 - Batch: 45] | Val loss: 2.3552 ]\n","[ Epoch: 0/560 - Batch: 50] | Val loss: 7.4617 ]\n","[ Epoch: 0/560 - Batch: 55] | Val loss: 2.9175 ]\n","[ Epoch: 0/560 - Batch: 60] | Val loss: 4.1580 ]\n","[ Epoch: 0/560 - Batch: 65] | Val loss: 3.0053 ]\n","[ Epoch: 0/560 - Batch: 70] | Val loss: 3.6783 ]\n","[ Epoch: 0/560 - Batch: 75] | Val loss: 5.4567 ]\n","[ Epoch: 0/560 - Batch: 80] | Val loss: 5.6227 ]\n","[ Epoch: 0/560 - Batch: 85] | Val loss: 4.2990 ]\n","[ Epoch: 0/560 - Batch: 90] | Val loss: 5.8001 ]\n","[ Epoch: 0/560 - Batch: 95] | Val loss: 11.8146 ]\n","[ Epoch: 0/560 - Batch: 100] | Val loss: 2.6933 ]\n","[ Epoch: 0/560 - Batch: 105] | Val loss: 7.0892 ]\n","[ Epoch: 0/560 - Batch: 110] | Val loss: 23.4928 ]\n","[ Epoch: 0/560 - Batch: 115] | Val loss: 8.0190 ]\n","[ Epoch: 0/560 - Batch: 120] | Val loss: 6.9380 ]\n","[ Epoch: 0/560 - Batch: 125] | Val loss: 14.1943 ]\n","[ Epoch: 0/560 - Batch: 130] | Val loss: 5.9178 ]\n","[ Epoch: 0/560 - Batch: 135] | Val loss: 7.4305 ]\n","[ Epoch: 0/560 - Batch: 140] | Val loss: 18.5318 ]\n","[ Epoch: 0/560 - Batch: 145] | Val loss: 26.8004 ]\n","[ Epoch: 0/560 - Batch: 150] | Val loss: 10.9700 ]\n","[ Epoch: 0/560 - Batch: 155] | Val loss: 27.6280 ]\n","[ Epoch: 0/560 - Batch: 160] | Val loss: 11.8478 ]\n","[ Epoch: 0/560 - Batch: 165] | Val loss: 17.0328 ]\n","[ Epoch: 0/560 - Batch: 170] | Val loss: 23.6560 ]\n","[ Epoch: 0/560 - Batch: 175] | Val loss: 6.6218 ]\n","[ Epoch: 0/560 - Batch: 180] | Val loss: 19.1428 ]\n","[ Epoch: 0/560 - Batch: 185] | Val loss: 26.6403 ]\n","\n","--------------------------------------------------------------\n","\n","\n","********************************************************************\n"," Train Time ... : 243.2942\n"," Train Loss ... : 3556.8326\n","....................................................................\n"," Val Time ..... : 102.1128\n"," Val Loss ..... : 2092.6487\n","....................................................................\n"," Mean ......... : 11.0722 \n"," Median ....... : 6.6218 \n"," Trimean ...... : 8.6303 \n"," Best 25% ..... : 3.2116 \n"," Worst 25% .... : 25.3243 \n"," Worst 5% ..... : 27.8945 \n","********************************************************************\n","\n","[ Epoch: 1/560 - Batch: 0 ] | [ Train loss: 21.3723 ]\n","[ Epoch: 1/560 - Batch: 5 ] | [ Train loss: 2.4748 ]\n","[ Epoch: 1/560 - Batch: 10 ] | [ Train loss: 19.3852 ]\n","[ Epoch: 1/560 - Batch: 15 ] | [ Train loss: 7.5011 ]\n","[ Epoch: 1/560 - Batch: 20 ] | [ Train loss: 13.6129 ]\n","[ Epoch: 1/560 - Batch: 25 ] | [ Train loss: 10.5362 ]\n","[ Epoch: 1/560 - Batch: 30 ] | [ Train loss: 2.5144 ]\n","[ Epoch: 1/560 - Batch: 35 ] | [ Train loss: 6.6218 ]\n","[ Epoch: 1/560 - Batch: 40 ] | [ Train loss: 4.3522 ]\n","[ Epoch: 1/560 - Batch: 45 ] | [ Train loss: 4.5825 ]\n","[ Epoch: 1/560 - Batch: 50 ] | [ Train loss: 4.4050 ]\n","[ Epoch: 1/560 - Batch: 55 ] | [ Train loss: 10.9839 ]\n","[ Epoch: 1/560 - Batch: 60 ] | [ Train loss: 1.5312 ]\n","[ Epoch: 1/560 - Batch: 65 ] | [ Train loss: 6.6623 ]\n","[ Epoch: 1/560 - Batch: 70 ] | [ Train loss: 1.1034 ]\n","[ Epoch: 1/560 - Batch: 75 ] | [ Train loss: 21.8060 ]\n","[ Epoch: 1/560 - Batch: 80 ] | [ Train loss: 2.8898 ]\n","[ Epoch: 1/560 - Batch: 85 ] | [ Train loss: 4.8306 ]\n","[ Epoch: 1/560 - Batch: 90 ] | [ Train loss: 2.5826 ]\n","[ Epoch: 1/560 - Batch: 95 ] | [ Train loss: 19.1713 ]\n","[ Epoch: 1/560 - Batch: 100 ] | [ Train loss: 2.0027 ]\n","[ Epoch: 1/560 - Batch: 105 ] | [ Train loss: 3.0041 ]\n","[ Epoch: 1/560 - Batch: 110 ] | [ Train loss: 7.4508 ]\n","[ Epoch: 1/560 - Batch: 115 ] | [ Train loss: 4.0938 ]\n","[ Epoch: 1/560 - Batch: 120 ] | [ Train loss: 20.0085 ]\n","[ Epoch: 1/560 - Batch: 125 ] | [ Train loss: 3.0165 ]\n","[ Epoch: 1/560 - Batch: 130 ] | [ Train loss: 2.6826 ]\n","[ Epoch: 1/560 - Batch: 135 ] | [ Train loss: 32.9115 ]\n","[ Epoch: 1/560 - Batch: 140 ] | [ Train loss: 11.2210 ]\n","[ Epoch: 1/560 - Batch: 145 ] | [ Train loss: 10.0839 ]\n","[ Epoch: 1/560 - Batch: 150 ] | [ Train loss: 0.8840 ]\n","[ Epoch: 1/560 - Batch: 155 ] | [ Train loss: 1.3958 ]\n","[ Epoch: 1/560 - Batch: 160 ] | [ Train loss: 3.2023 ]\n","[ Epoch: 1/560 - Batch: 165 ] | [ Train loss: 4.7494 ]\n","[ Epoch: 1/560 - Batch: 170 ] | [ Train loss: 4.2602 ]\n","[ Epoch: 1/560 - Batch: 175 ] | [ Train loss: 24.9597 ]\n","[ Epoch: 1/560 - Batch: 180 ] | [ Train loss: 22.3779 ]\n","[ Epoch: 1/560 - Batch: 185 ] | [ Train loss: 4.5088 ]\n","[ Epoch: 1/560 - Batch: 190 ] | [ Train loss: 3.1224 ]\n","[ Epoch: 1/560 - Batch: 195 ] | [ Train loss: 0.7623 ]\n","[ Epoch: 1/560 - Batch: 200 ] | [ Train loss: 19.0172 ]\n","[ Epoch: 1/560 - Batch: 205 ] | [ Train loss: 3.4555 ]\n","[ Epoch: 1/560 - Batch: 210 ] | [ Train loss: 5.4896 ]\n","[ Epoch: 1/560 - Batch: 215 ] | [ Train loss: 1.2622 ]\n","[ Epoch: 1/560 - Batch: 220 ] | [ Train loss: 1.6929 ]\n","[ Epoch: 1/560 - Batch: 225 ] | [ Train loss: 1.6122 ]\n","[ Epoch: 1/560 - Batch: 230 ] | [ Train loss: 1.1837 ]\n","[ Epoch: 1/560 - Batch: 235 ] | [ Train loss: 4.2586 ]\n","[ Epoch: 1/560 - Batch: 240 ] | [ Train loss: 20.1371 ]\n","[ Epoch: 1/560 - Batch: 245 ] | [ Train loss: 1.2139 ]\n","[ Epoch: 1/560 - Batch: 250 ] | [ Train loss: 1.4992 ]\n","[ Epoch: 1/560 - Batch: 255 ] | [ Train loss: 5.8708 ]\n","[ Epoch: 1/560 - Batch: 260 ] | [ Train loss: 0.3007 ]\n","[ Epoch: 1/560 - Batch: 265 ] | [ Train loss: 1.7120 ]\n","[ Epoch: 1/560 - Batch: 270 ] | [ Train loss: 8.6890 ]\n","[ Epoch: 1/560 - Batch: 275 ] | [ Train loss: 5.6068 ]\n","[ Epoch: 1/560 - Batch: 280 ] | [ Train loss: 17.5480 ]\n","[ Epoch: 1/560 - Batch: 285 ] | [ Train loss: 3.7961 ]\n","[ Epoch: 1/560 - Batch: 290 ] | [ Train loss: 17.9679 ]\n","[ Epoch: 1/560 - Batch: 295 ] | [ Train loss: 3.6954 ]\n","[ Epoch: 1/560 - Batch: 300 ] | [ Train loss: 2.1677 ]\n","[ Epoch: 1/560 - Batch: 305 ] | [ Train loss: 1.2766 ]\n","[ Epoch: 1/560 - Batch: 310 ] | [ Train loss: 4.1040 ]\n","[ Epoch: 1/560 - Batch: 315 ] | [ Train loss: 22.4206 ]\n","[ Epoch: 1/560 - Batch: 320 ] | [ Train loss: 3.0559 ]\n","[ Epoch: 1/560 - Batch: 325 ] | [ Train loss: 1.5520 ]\n","[ Epoch: 1/560 - Batch: 330 ] | [ Train loss: 19.0453 ]\n","[ Epoch: 1/560 - Batch: 335 ] | [ Train loss: 15.5818 ]\n","[ Epoch: 1/560 - Batch: 340 ] | [ Train loss: 4.3287 ]\n","[ Epoch: 1/560 - Batch: 345 ] | [ Train loss: 2.2149 ]\n","[ Epoch: 1/560 - Batch: 350 ] | [ Train loss: 3.3702 ]\n","[ Epoch: 1/560 - Batch: 355 ] | [ Train loss: 3.2214 ]\n","[ Epoch: 1/560 - Batch: 360 ] | [ Train loss: 13.3401 ]\n","[ Epoch: 1/560 - Batch: 365 ] | [ Train loss: 5.0776 ]\n","[ Epoch: 1/560 - Batch: 370 ] | [ Train loss: 4.0419 ]\n","[ Epoch: 1/560 - Batch: 375 ] | [ Train loss: 3.7878 ]\n","\n","********************************************************************\n"," Train Time ... : 267.8211\n"," Train Loss ... : 2874.7836\n","********************************************************************\n","\n","[ Epoch: 2/560 - Batch: 0 ] | [ Train loss: 1.4512 ]\n","[ Epoch: 2/560 - Batch: 5 ] | [ Train loss: 3.4311 ]\n","[ Epoch: 2/560 - Batch: 10 ] | [ Train loss: 27.9399 ]\n","[ Epoch: 2/560 - Batch: 15 ] | [ Train loss: 22.0499 ]\n","[ Epoch: 2/560 - Batch: 20 ] | [ Train loss: 3.3930 ]\n","[ Epoch: 2/560 - Batch: 25 ] | [ Train loss: 3.6376 ]\n","[ Epoch: 2/560 - Batch: 30 ] | [ Train loss: 16.9854 ]\n","[ Epoch: 2/560 - Batch: 35 ] | [ Train loss: 8.4876 ]\n","[ Epoch: 2/560 - Batch: 40 ] | [ Train loss: 4.2379 ]\n","[ Epoch: 2/560 - Batch: 45 ] | [ Train loss: 15.3172 ]\n","[ Epoch: 2/560 - Batch: 50 ] | [ Train loss: 16.1290 ]\n","[ Epoch: 2/560 - Batch: 55 ] | [ Train loss: 13.0644 ]\n","[ Epoch: 2/560 - Batch: 60 ] | [ Train loss: 2.8517 ]\n","[ Epoch: 2/560 - Batch: 65 ] | [ Train loss: 1.8758 ]\n","[ Epoch: 2/560 - Batch: 70 ] | [ Train loss: 3.2793 ]\n","[ Epoch: 2/560 - Batch: 75 ] | [ Train loss: 7.5729 ]\n","[ Epoch: 2/560 - Batch: 80 ] | [ Train loss: 2.6083 ]\n","[ Epoch: 2/560 - Batch: 85 ] | [ Train loss: 0.9760 ]\n","[ Epoch: 2/560 - Batch: 90 ] | [ Train loss: 2.7775 ]\n","[ Epoch: 2/560 - Batch: 95 ] | [ Train loss: 1.4602 ]\n","[ Epoch: 2/560 - Batch: 100 ] | [ Train loss: 18.2341 ]\n","[ Epoch: 2/560 - Batch: 105 ] | [ Train loss: 11.0258 ]\n","[ Epoch: 2/560 - Batch: 110 ] | [ Train loss: 3.3167 ]\n","[ Epoch: 2/560 - Batch: 115 ] | [ Train loss: 22.0439 ]\n","[ Epoch: 2/560 - Batch: 120 ] | [ Train loss: 5.1427 ]\n","[ Epoch: 2/560 - Batch: 125 ] | [ Train loss: 4.2568 ]\n","[ Epoch: 2/560 - Batch: 130 ] | [ Train loss: 10.0091 ]\n","[ Epoch: 2/560 - Batch: 135 ] | [ Train loss: 3.4452 ]\n","[ Epoch: 2/560 - Batch: 140 ] | [ Train loss: 5.0255 ]\n","[ Epoch: 2/560 - Batch: 145 ] | [ Train loss: 10.1290 ]\n","[ Epoch: 2/560 - Batch: 150 ] | [ Train loss: 9.3478 ]\n","[ Epoch: 2/560 - Batch: 155 ] | [ Train loss: 4.5139 ]\n","[ Epoch: 2/560 - Batch: 160 ] | [ Train loss: 4.9739 ]\n","[ Epoch: 2/560 - Batch: 165 ] | [ Train loss: 4.4453 ]\n","[ Epoch: 2/560 - Batch: 170 ] | [ Train loss: 5.3395 ]\n","[ Epoch: 2/560 - Batch: 175 ] | [ Train loss: 2.6983 ]\n","[ Epoch: 2/560 - Batch: 180 ] | [ Train loss: 4.7550 ]\n","[ Epoch: 2/560 - Batch: 185 ] | [ Train loss: 21.8288 ]\n","[ Epoch: 2/560 - Batch: 190 ] | [ Train loss: 0.9506 ]\n","[ Epoch: 2/560 - Batch: 195 ] | [ Train loss: 1.9429 ]\n","[ Epoch: 2/560 - Batch: 200 ] | [ Train loss: 9.9622 ]\n","[ Epoch: 2/560 - Batch: 205 ] | [ Train loss: 2.6690 ]\n","[ Epoch: 2/560 - Batch: 210 ] | [ Train loss: 0.8754 ]\n","[ Epoch: 2/560 - Batch: 215 ] | [ Train loss: 2.3582 ]\n","[ Epoch: 2/560 - Batch: 220 ] | [ Train loss: 5.2636 ]\n","[ Epoch: 2/560 - Batch: 225 ] | [ Train loss: 20.9571 ]\n","[ Epoch: 2/560 - Batch: 230 ] | [ Train loss: 6.5595 ]\n","[ Epoch: 2/560 - Batch: 235 ] | [ Train loss: 1.8222 ]\n","[ Epoch: 2/560 - Batch: 240 ] | [ Train loss: 1.7690 ]\n","[ Epoch: 2/560 - Batch: 245 ] | [ Train loss: 15.8881 ]\n","[ Epoch: 2/560 - Batch: 250 ] | [ Train loss: 11.1062 ]\n","[ Epoch: 2/560 - Batch: 255 ] | [ Train loss: 2.1545 ]\n","[ Epoch: 2/560 - Batch: 260 ] | [ Train loss: 2.0556 ]\n","[ Epoch: 2/560 - Batch: 265 ] | [ Train loss: 3.8339 ]\n","[ Epoch: 2/560 - Batch: 270 ] | [ Train loss: 2.5727 ]\n","[ Epoch: 2/560 - Batch: 275 ] | [ Train loss: 32.2429 ]\n","[ Epoch: 2/560 - Batch: 280 ] | [ Train loss: 3.1597 ]\n","[ Epoch: 2/560 - Batch: 285 ] | [ Train loss: 0.9810 ]\n","[ Epoch: 2/560 - Batch: 290 ] | [ Train loss: 5.3600 ]\n","[ Epoch: 2/560 - Batch: 295 ] | [ Train loss: 4.1790 ]\n","[ Epoch: 2/560 - Batch: 300 ] | [ Train loss: 4.4429 ]\n","[ Epoch: 2/560 - Batch: 305 ] | [ Train loss: 5.0319 ]\n","[ Epoch: 2/560 - Batch: 310 ] | [ Train loss: 0.8147 ]\n","[ Epoch: 2/560 - Batch: 315 ] | [ Train loss: 18.5983 ]\n","[ Epoch: 2/560 - Batch: 320 ] | [ Train loss: 15.8466 ]\n","[ Epoch: 2/560 - Batch: 325 ] | [ Train loss: 6.1527 ]\n","[ Epoch: 2/560 - Batch: 330 ] | [ Train loss: 1.4312 ]\n","[ Epoch: 2/560 - Batch: 335 ] | [ Train loss: 15.7867 ]\n","[ Epoch: 2/560 - Batch: 340 ] | [ Train loss: 7.2504 ]\n","[ Epoch: 2/560 - Batch: 345 ] | [ Train loss: 1.2667 ]\n","[ Epoch: 2/560 - Batch: 350 ] | [ Train loss: 3.0017 ]\n","[ Epoch: 2/560 - Batch: 355 ] | [ Train loss: 0.8276 ]\n","[ Epoch: 2/560 - Batch: 360 ] | [ Train loss: 0.1897 ]\n","[ Epoch: 2/560 - Batch: 365 ] | [ Train loss: 24.1155 ]\n","[ Epoch: 2/560 - Batch: 370 ] | [ Train loss: 10.8048 ]\n","[ Epoch: 2/560 - Batch: 375 ] | [ Train loss: 33.5714 ]\n","\n","********************************************************************\n"," Train Time ... : 226.5833\n"," Train Loss ... : 2759.3801\n","********************************************************************\n","\n","[ Epoch: 3/560 - Batch: 0 ] | [ Train loss: 1.3549 ]\n","[ Epoch: 3/560 - Batch: 5 ] | [ Train loss: 2.3160 ]\n","[ Epoch: 3/560 - Batch: 10 ] | [ Train loss: 6.5271 ]\n","[ Epoch: 3/560 - Batch: 15 ] | [ Train loss: 12.3976 ]\n","[ Epoch: 3/560 - Batch: 20 ] | [ Train loss: 2.1238 ]\n","[ Epoch: 3/560 - Batch: 25 ] | [ Train loss: 8.0133 ]\n","[ Epoch: 3/560 - Batch: 30 ] | [ Train loss: 5.2154 ]\n","[ Epoch: 3/560 - Batch: 35 ] | [ Train loss: 1.7192 ]\n","[ Epoch: 3/560 - Batch: 40 ] | [ Train loss: 5.9543 ]\n","[ Epoch: 3/560 - Batch: 45 ] | [ Train loss: 2.0813 ]\n","[ Epoch: 3/560 - Batch: 50 ] | [ Train loss: 0.9768 ]\n","[ Epoch: 3/560 - Batch: 55 ] | [ Train loss: 18.4610 ]\n","[ Epoch: 3/560 - Batch: 60 ] | [ Train loss: 4.6923 ]\n","[ Epoch: 3/560 - Batch: 65 ] | [ Train loss: 5.5387 ]\n","[ Epoch: 3/560 - Batch: 70 ] | [ Train loss: 2.0863 ]\n","[ Epoch: 3/560 - Batch: 75 ] | [ Train loss: 2.0512 ]\n","[ Epoch: 3/560 - Batch: 80 ] | [ Train loss: 2.5655 ]\n","[ Epoch: 3/560 - Batch: 85 ] | [ Train loss: 1.5886 ]\n","[ Epoch: 3/560 - Batch: 90 ] | [ Train loss: 2.2805 ]\n","[ Epoch: 3/560 - Batch: 95 ] | [ Train loss: 2.0366 ]\n","[ Epoch: 3/560 - Batch: 100 ] | [ Train loss: 16.8558 ]\n","[ Epoch: 3/560 - Batch: 105 ] | [ Train loss: 0.9994 ]\n","[ Epoch: 3/560 - Batch: 110 ] | [ Train loss: 12.5932 ]\n","[ Epoch: 3/560 - Batch: 115 ] | [ Train loss: 3.8901 ]\n","[ Epoch: 3/560 - Batch: 120 ] | [ Train loss: 0.7089 ]\n","[ Epoch: 3/560 - Batch: 125 ] | [ Train loss: 5.6004 ]\n","[ Epoch: 3/560 - Batch: 130 ] | [ Train loss: 23.7437 ]\n","[ Epoch: 3/560 - Batch: 135 ] | [ Train loss: 32.5780 ]\n","[ Epoch: 3/560 - Batch: 140 ] | [ Train loss: 3.8037 ]\n","[ Epoch: 3/560 - Batch: 145 ] | [ Train loss: 2.7543 ]\n","[ Epoch: 3/560 - Batch: 150 ] | [ Train loss: 3.6471 ]\n","[ Epoch: 3/560 - Batch: 155 ] | [ Train loss: 22.0412 ]\n","[ Epoch: 3/560 - Batch: 160 ] | [ Train loss: 17.9011 ]\n","[ Epoch: 3/560 - Batch: 165 ] | [ Train loss: 3.0220 ]\n","[ Epoch: 3/560 - Batch: 170 ] | [ Train loss: 0.1219 ]\n","[ Epoch: 3/560 - Batch: 175 ] | [ Train loss: 8.8513 ]\n","[ Epoch: 3/560 - Batch: 180 ] | [ Train loss: 10.2819 ]\n","[ Epoch: 3/560 - Batch: 185 ] | [ Train loss: 6.4534 ]\n","[ Epoch: 3/560 - Batch: 190 ] | [ Train loss: 17.8340 ]\n","[ Epoch: 3/560 - Batch: 195 ] | [ Train loss: 4.5818 ]\n","[ Epoch: 3/560 - Batch: 200 ] | [ Train loss: 3.8932 ]\n","[ Epoch: 3/560 - Batch: 205 ] | [ Train loss: 0.3438 ]\n","[ Epoch: 3/560 - Batch: 210 ] | [ Train loss: 0.7269 ]\n","[ Epoch: 3/560 - Batch: 215 ] | [ Train loss: 3.1235 ]\n","[ Epoch: 3/560 - Batch: 220 ] | [ Train loss: 3.8655 ]\n","[ Epoch: 3/560 - Batch: 225 ] | [ Train loss: 5.0908 ]\n","[ Epoch: 3/560 - Batch: 230 ] | [ Train loss: 4.7728 ]\n","[ Epoch: 3/560 - Batch: 235 ] | [ Train loss: 4.0079 ]\n","[ Epoch: 3/560 - Batch: 240 ] | [ Train loss: 27.4951 ]\n","[ Epoch: 3/560 - Batch: 245 ] | [ Train loss: 3.6718 ]\n","[ Epoch: 3/560 - Batch: 250 ] | [ Train loss: 0.2961 ]\n","[ Epoch: 3/560 - Batch: 255 ] | [ Train loss: 17.6451 ]\n","[ Epoch: 3/560 - Batch: 260 ] | [ Train loss: 3.1470 ]\n","[ Epoch: 3/560 - Batch: 265 ] | [ Train loss: 10.5408 ]\n","[ Epoch: 3/560 - Batch: 270 ] | [ Train loss: 2.1294 ]\n","[ Epoch: 3/560 - Batch: 275 ] | [ Train loss: 6.1382 ]\n","[ Epoch: 3/560 - Batch: 280 ] | [ Train loss: 3.5143 ]\n","[ Epoch: 3/560 - Batch: 285 ] | [ Train loss: 2.7976 ]\n","[ Epoch: 3/560 - Batch: 290 ] | [ Train loss: 1.5038 ]\n","[ Epoch: 3/560 - Batch: 295 ] | [ Train loss: 6.3637 ]\n","[ Epoch: 3/560 - Batch: 300 ] | [ Train loss: 13.8738 ]\n","[ Epoch: 3/560 - Batch: 305 ] | [ Train loss: 3.9408 ]\n","[ Epoch: 3/560 - Batch: 310 ] | [ Train loss: 1.1368 ]\n","[ Epoch: 3/560 - Batch: 315 ] | [ Train loss: 19.5826 ]\n","[ Epoch: 3/560 - Batch: 320 ] | [ Train loss: 9.4254 ]\n","[ Epoch: 3/560 - Batch: 325 ] | [ Train loss: 17.2893 ]\n","[ Epoch: 3/560 - Batch: 330 ] | [ Train loss: 2.6840 ]\n","[ Epoch: 3/560 - Batch: 335 ] | [ Train loss: 3.6060 ]\n","[ Epoch: 3/560 - Batch: 340 ] | [ Train loss: 0.9413 ]\n","[ Epoch: 3/560 - Batch: 345 ] | [ Train loss: 2.0218 ]\n","[ Epoch: 3/560 - Batch: 350 ] | [ Train loss: 0.3779 ]\n","[ Epoch: 3/560 - Batch: 355 ] | [ Train loss: 0.7449 ]\n","[ Epoch: 3/560 - Batch: 360 ] | [ Train loss: 0.7436 ]\n","[ Epoch: 3/560 - Batch: 365 ] | [ Train loss: 23.6748 ]\n","[ Epoch: 3/560 - Batch: 370 ] | [ Train loss: 11.2725 ]\n","[ Epoch: 3/560 - Batch: 375 ] | [ Train loss: 4.7262 ]\n","\n","********************************************************************\n"," Train Time ... : 239.5727\n"," Train Loss ... : 2741.5252\n","********************************************************************\n","\n","[ Epoch: 4/560 - Batch: 0 ] | [ Train loss: 0.5223 ]\n","[ Epoch: 4/560 - Batch: 5 ] | [ Train loss: 22.5594 ]\n","[ Epoch: 4/560 - Batch: 10 ] | [ Train loss: 0.6989 ]\n","[ Epoch: 4/560 - Batch: 15 ] | [ Train loss: 2.9938 ]\n","[ Epoch: 4/560 - Batch: 20 ] | [ Train loss: 0.3257 ]\n","[ Epoch: 4/560 - Batch: 25 ] | [ Train loss: 6.5420 ]\n","[ Epoch: 4/560 - Batch: 30 ] | [ Train loss: 2.3567 ]\n","[ Epoch: 4/560 - Batch: 35 ] | [ Train loss: 10.8597 ]\n","[ Epoch: 4/560 - Batch: 40 ] | [ Train loss: 1.9852 ]\n","[ Epoch: 4/560 - Batch: 45 ] | [ Train loss: 4.1196 ]\n","[ Epoch: 4/560 - Batch: 50 ] | [ Train loss: 2.3780 ]\n","[ Epoch: 4/560 - Batch: 55 ] | [ Train loss: 0.8195 ]\n","[ Epoch: 4/560 - Batch: 60 ] | [ Train loss: 2.1424 ]\n","[ Epoch: 4/560 - Batch: 65 ] | [ Train loss: 2.6098 ]\n","[ Epoch: 4/560 - Batch: 70 ] | [ Train loss: 0.2407 ]\n","[ Epoch: 4/560 - Batch: 75 ] | [ Train loss: 22.8668 ]\n","[ Epoch: 4/560 - Batch: 80 ] | [ Train loss: 3.1276 ]\n","[ Epoch: 4/560 - Batch: 85 ] | [ Train loss: 3.1798 ]\n","[ Epoch: 4/560 - Batch: 90 ] | [ Train loss: 2.3631 ]\n","[ Epoch: 4/560 - Batch: 95 ] | [ Train loss: 15.5800 ]\n","[ Epoch: 4/560 - Batch: 100 ] | [ Train loss: 4.0782 ]\n","[ Epoch: 4/560 - Batch: 105 ] | [ Train loss: 2.1980 ]\n","[ Epoch: 4/560 - Batch: 110 ] | [ Train loss: 11.1955 ]\n","[ Epoch: 4/560 - Batch: 115 ] | [ Train loss: 6.1691 ]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-af7b4993f7ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["log_data = pd.DataFrame(columns = [\"train_loss\", \"val_loss\", \"mean\", \"median\", \"trimean\", \"bst25\", \"wst25\", \"wst5\"])\n","\n","fold_num, epochs, batch_size, lr = 0, 560, 1, 0.0003 \n","\n","model = ModelFC4()\n","model.set_optimizer(lr)\n","\n","training_set = ColorCheckerDataset(train=True, folds_num=fold_num)\n","training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, num_workers=20, drop_last=True)\n","\n","test_set = ColorCheckerDataset(train=False, folds_num=fold_num)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=20, drop_last=True)\n","\n","train_loss, val_loss = 0, 0\n","\n","for epoch in range(epochs):\n","\n","    model.train_mode()\n","    train_loss = 0\n","    start = time.time()\n","\n","    for i, (image, label, _) in enumerate(training_loader):\n","        image, label = image.to(DEVICE), label.to(DEVICE)\n","        loss = model.optimize(image, label)\n","        train_loss += loss\n","\n","        if i % 5 == 0:\n","            print(\"[ Epoch: {}/{} - Batch: {} ] | [ Train loss: {:.4f} ]\".format(epoch, epochs, i, loss))\n","\n","    train_time = time.time() - start\n","\n","    val_loss = 0\n","    start = time.time()\n","\n","    if epoch % 5 == 0:\n","        model.evaluation_mode()\n","        errors = []\n","        print(\"\\n--------------------------------------------------------------\")\n","        print(\"\\t\\t\\t Validation\")\n","        print(\"--------------------------------------------------------------\\n\")\n","\n","        with torch.no_grad():\n","            for i, (image, label, file_name) in enumerate(test_loader):\n","                image, label = image.to(DEVICE), label.to(DEVICE)\n","                pred = model.predict(image)\n","                loss = model.get_loss(pred, label).item()\n","                val_loss += loss\n","                errors.append(model.get_loss(pred, label).item())\n","\n","                if i % 5 == 0:\n","                    print(\"[ Epoch: {}/{} - Batch: {}] | Val loss: {:.4f} ]\".format(epoch, epochs, i, loss))\n","\n","                img_id = file_name[0].split(\".\")[0]\n","        print(\"\\n--------------------------------------------------------------\\n\")\n","\n","    val_time = time.time() - start\n","\n","    metrics = compute_metrics(errors)\n","    metrics['train_loss'] = train_loss\n","    metrics['val_loss'] = val_loss\n","    df_dictionary = pd.DataFrame([metrics])\n","    log_data = pd.concat([log_data, df_dictionary], ignore_index=True)\n","    print(\"\\n********************************************************************\")\n","    print(\" Train Time ... : {:.4f}\".format(train_time))\n","    print(\" Train Loss ... : {:.4f}\".format(train_loss))\n","    if val_time > 0.1:\n","      print(\"....................................................................\")\n","      print(\" Val Time ..... : {:.4f}\".format(val_time))\n","      print(\" Val Loss ..... : {:.4f}\".format(val_loss))\n","      print(\"....................................................................\")\n","      print_metrics(metrics)\n","    print(\"********************************************************************\\n\")\n"]},{"cell_type":"code","source":["log_data.min()"],"metadata":{"id":"iDTjQudoRw-N","executionInfo":{"status":"aborted","timestamp":1650873086984,"user_tz":-180,"elapsed":29,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (15,10))\n","\n","plt.plot([i for i in range(len(log_data['mean']))], log_data['mean'], label = 'Mean')\n","plt.xlabel('Epochs')\n","plt.ylabel('Mean')\n","plt.legend();"],"metadata":{"id":"ybgSDyChTBID","executionInfo":{"status":"aborted","timestamp":1650873086987,"user_tz":-180,"elapsed":30,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.utils import save_image\n","from torchvision.transforms import transforms"],"metadata":{"id":"GugaMDLVTQ0G","executionInfo":{"status":"aborted","timestamp":1650873086988,"user_tz":-180,"elapsed":30,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image, label, file_name =  next(test_loader)\n","save_image(image, 'image_ippi.png')\n","out = model.predict(image)\n","original = transforms.ToPILImage()(image.squeeze()).convert(\"RGB\")\n","ans = correct(original, out)\n","conv_t = transforms.ToTensor()\n","save_image(conv_t(ans), 'image_ans_ippi.png')"],"metadata":{"id":"HPMzzP5fUTQc","executionInfo":{"status":"aborted","timestamp":1650873086989,"user_tz":-180,"elapsed":30,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","jupyter nbconvert --to html \"/content/Model_(1) (1).ipynb\""],"metadata":{"id":"JfX2bDuTV5AH","executionInfo":{"status":"aborted","timestamp":1650873086990,"user_tz":-180,"elapsed":31,"user":{"displayName":"Артур Вадимович Заяц","userId":"14357740445412681610"}}},"execution_count":null,"outputs":[]}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"colab":{"name":"Model (1).ipynb","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1ce3ab0036d846bda693f226fa75cdc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8666408c9903449ab5c7b0c13930a756","IPY_MODEL_cdc87b7187fd4c17be4bd91891aee2b0","IPY_MODEL_7698cb66aa174de1b64066c4fc232d10"],"layout":"IPY_MODEL_16bac13981a04295b6154846a50044b0"}},"8666408c9903449ab5c7b0c13930a756":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f138b3286178493c93b9dac31f15a068","placeholder":"​","style":"IPY_MODEL_3b8c2062c20d44ed966e42c8565f7570","value":"100%"}},"cdc87b7187fd4c17be4bd91891aee2b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6369962eefa492a975cde1a363c8a16","max":244408911,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa5271a172644112a038495d8b2edb32","value":244408911}},"7698cb66aa174de1b64066c4fc232d10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d37ece3ebff4a08b4973544d8eac121","placeholder":"​","style":"IPY_MODEL_0fc17e13e2244b5dab90ea9b90195a3c","value":" 233M/233M [00:01&lt;00:00, 137MB/s]"}},"16bac13981a04295b6154846a50044b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f138b3286178493c93b9dac31f15a068":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b8c2062c20d44ed966e42c8565f7570":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6369962eefa492a975cde1a363c8a16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5271a172644112a038495d8b2edb32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d37ece3ebff4a08b4973544d8eac121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fc17e13e2244b5dab90ea9b90195a3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}